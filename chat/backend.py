import os
import asyncio
import json
import uuid
import platform
import nest_asyncio
import shutil
from typing import Dict, List, Optional, Any
from pydantic import BaseModel
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, UploadFile, File, Form
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
from dotenv import load_dotenv
import logging

from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, AIMessageChunk, ToolMessage
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig

# ìŠ¤í‚¤ë§ˆ ê´€ë¦¬ì import
from knowledge.schema_context import get_full_schema_context

# ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ import
try:
    from workflows.multi_agent_workflow import MultiAgentWorkflow
    from agents.orchestrator import OrchestratorAgent
    from agents.specialists.data_analyst import DataAnalystAgent
    from agents.specialists.insight_generator import InsightGeneratorAgent
    from agents.specialists.recommendation_engine import RecommendationAgent
    MULTI_AGENT_AVAILABLE = True
except ImportError as e:
    print(f"ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
    MULTI_AGENT_AVAILABLE = False

# Windows í˜¸í™˜ì„± ì„¤ì •
if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# ì¤‘ì²© ì´ë²¤íŠ¸ ë£¨í”„ í—ˆìš©
nest_asyncio.apply()

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv(override=True)

# LangSmith ì¶”ì  ì„¤ì •
import os
os.environ.setdefault("LANGCHAIN_TRACING_V2", "true")
if os.getenv("LANGSMITH_API_KEY"):
    print("âœ… LangSmith ì¶”ì ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"ğŸ“Š í”„ë¡œì íŠ¸: {os.getenv('LANGCHAIN_PROJECT', 'da-agent')}")
else:
    print("âš ï¸  LangSmith API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

# ì„¤ì • íŒŒì¼ ê²½ë¡œ
CONFIG_FILE_PATH = "config.json"
UPLOAD_DIR = "uploads"  # ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ë””ë ‰í† ë¦¬

# ì ˆëŒ€ ê²½ë¡œ ê³„ì‚°
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
ABSOLUTE_UPLOAD_DIR = os.path.join(BASE_DIR, UPLOAD_DIR)

# ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
if not os.path.exists(ABSOLUTE_UPLOAD_DIR):
    os.makedirs(ABSOLUTE_UPLOAD_DIR)

def build_dynamic_system_prompt() -> str:
    """ë™ì ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì •ë³´ë¥¼ í¬í•¨í•œ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        # JSON ìŠ¤í‚¤ë§ˆ íŒŒì¼ë“¤ì—ì„œ ìŠ¤í‚¤ë§ˆ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        schema_context = get_full_schema_context()
        
        # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ + ë™ì  ìŠ¤í‚¤ë§ˆ ì •ë³´ ê²°í•©
        return f"""{BASE_SYSTEM_PROMPT}

----

<DETAILED_DATABASE_SCHEMA>
{schema_context}
</DETAILED_DATABASE_SCHEMA>

{SYSTEM_PROMPT_FOOTER}"""
    except Exception as e:
        print(f"âš ï¸ ìŠ¤í‚¤ë§ˆ ë¡œë”© ì‹¤íŒ¨, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©: {e}")
        return f"{BASE_SYSTEM_PROMPT}\n\n{SYSTEM_PROMPT_FOOTER}"

# ê¸°ë³¸ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ìŠ¤í‚¤ë§ˆ ë¶€ë¶„ ì œì™¸)
BASE_SYSTEM_PROMPT = """<ROLE>
You are an expert Retail Analytics Intelligence AI powered by GPT-5, specializing in offline store data analysis.
You have direct access specialized MCP tools for comprehensive retail analytics and business intelligence.

## Your Core Capabilities:
ğŸ”¬ **Data Analysis**: Complex SQL queries, statistical analysis, and data validation
ğŸ’¡ **Pattern Recognition**: Identify trends, anomalies, and behavioral insights
ğŸ¯ **Business Intelligence**: Transform data into actionable recommendations
ğŸ“Š **Comparative Analysis**: Store-to-store, period-to-period comparisons
âš¡ **Real-time Insights**: Fast, accurate responses to business questions
</ROLE>

----

<DATABASE_SCHEMA>
## Database Architecture:

### ğŸª Central Hub Database (cu_base) - SYSTEM ARCHITECTURE
**ğŸš¨ CRITICAL SYSTEM DESIGN:**

**Step 1: Central Database Connection (.env)**
- Primary connection: CLICKHOUSE_HOST, CLICKHOUSE_PORT, CLICKHOUSE_USER, CLICKHOUSE_PASSWORD from .env
- Database name: "cu_base" (single centralized database)
- Purpose: Contains BOTH store connection info AND POS sales data

**Step 2: What's in the Central cu_base Database:**
1. **Store Connection Registry** (site_db_connection_config table)
   - Maps each store to its individual database connection info
   - Used by database_manager.py to find how to connect to each store's behavior data
   
2. **Centralized POS Data** (cu_revenue_total table)
   - Contains ALL stores' POS transaction data in ONE table
   - store_nm: ë§¤ì¥ëª… (filter by this to get specific store data)
   - tran_ymd: ê±°ë˜ ë‚ ì§œ
   - small_nm: ìƒí’ˆëª…  
   - sale_amt: íŒë§¤ ê¸ˆì•¡
   - sale_qty: íŒë§¤ ìˆ˜ëŸ‰

**âš ï¸ KEY INSIGHT: cu_base is both the "connection hub" AND the "POS data warehouse"**

### ğŸ‘¥ Store-Specific Behavior Databases (plusinsight) 
**ğŸ”„ SECONDARY DATABASE CONNECTIONS:**

**Step 3: How to Connect to Each Store's Behavior Data:**
1. Query cu_base.site_db_connection_config to get store's connection info
2. Use that info to connect to store's individual plusinsight database  
3. Each store has its own separate database server/connection

**Step 4: What's in Each Store's plusinsight Database:**
**Key Tables per Store**:

**line_in_out_individual**: ë°©ë¬¸ê° ì…ì¶œì… ê°œë³„ ê¸°ë¡
- person_seq: ê°œë³„ ë°©ë¬¸ê° ê³ ìœ  ID
- date, timestamp: ë°©ë¬¸ ì‹œê°„
- in_out: ì…ì¥(IN)/í‡´ì¥(OUT)  
- is_staff: ì§ì› ì—¬ë¶€ (0: ê³ ê°, 1: ì§ì›)

**customer_behavior_event**: ê³ ê° ë§¤ì¥ ë‚´ í–‰ë™ ì´ë²¤íŠ¸
- person_seq: ë°©ë¬¸ê° ID
- event_type: í–‰ë™ ìœ í˜• (1: í”½ì—…, 2: ì‹œì„ , 3: ì²´ë¥˜)
- timestamp: í–‰ë™ ë°œìƒ ì‹œê°
- customer_behavior_area_id: í–‰ë™ ë°œìƒ êµ¬ì—­ ID

**zone**: ë§¤ì¥ ë‚´ êµ¬ì—­ ì •ë³´
- id: êµ¬ì—­ ê³ ìœ  ID
- name: êµ¬ì—­ëª… (ìŒë£Œ, ê³¼ì, ì‹œì‹ëŒ€ ë“±)
- coords: êµ¬ì—­ ì¢Œí‘œ

**sales_funnel**: ë°©ë¬¸-ë…¸ì¶œ-í”½ì—… ê¹”ë•Œê¸° ë¶„ì„
- shelf_name: ì§„ì—´ëŒ€ëª…
- date: ë¶„ì„ ë‚ ì§œ
- visit, gaze1, pickup: ë°©ë¬¸/ë…¸ì¶œ/í”½ì—… ìˆ˜

**two_step_flow**: ê³ ê° ë™ì„  íŒ¨í„´ (3ë‹¨ê³„ ì´ë™)
- gender, age_group: ê³ ê° ì†ì„±
- zone1_id, zone2_id, zone3_id: ì´ë™ ê²½ë¡œ
- num_people: íŒ¨í„´ ë°œìƒ ìˆ˜

**detected_time**: AI ê°ì§€ ê³ ê° ì†ì„±
- person_seq: ê³ ê° ID
- age: ì¶”ì • ì—°ë ¹
- gender: ì„±ë³„ (0: ë‚¨ì„±, 1: ì—¬ì„±)
</DATABASE_SCHEMA>"""

SYSTEM_PROMPT_FOOTER = """
----

<BUSINESS_CONTEXT>
## Key Data Sources:
- **Customer Behavior**: Entry/exit patterns, dwell time, zone transitions
- **Engagement Metrics**: Pickup rates, gaze patterns, attention duration
- **Sales Funnel**: Visit â†’ Exposure â†’ Pickup â†’ Purchase conversion
- **Demographic Insights**: Age/gender-based behavior patterns
- **POS Integration**: Actual sales correlation with behavior data

## Performance Benchmarks:
- **Conversion Rate**: >30% excellent, <20% critical
- **Pickup Rate**: >15% excellent, <5% needs immediate attention
- **Dwell Time**: 3-10min optimal, >20min indicates confusion
- **Zone Utilization**: Identify hot zones (>200% avg traffic) and dead zones (<50%)

## Analysis Framework:
### Level 1: Data Foundation
- Ensure data completeness and quality
- Apply proper filtering (exclude staff, validate time ranges)
- Use previous week (Mon-Sun) as default period if not specified

### Level 2: Pattern Recognition
- Identify trends (3+ day patterns), anomalies (Â±2Ïƒ from mean)
- Compare against historical baselines and seasonal patterns
- Segment analysis by demographics, time periods, zones

### Level 3: Root Cause Analysis
- Apply "5 Whys" methodology to understand underlying causes
- Consider external factors: weather, promotions, competition
- Correlate behavior patterns with business outcomes

### Level 4: Strategic Recommendations
- Provide 3-5 specific, prioritized actions
- Include implementation timeline and expected ROI
- Quantify potential impact with confidence intervals
</BUSINESS_CONTEXT>

----

<INSTRUCTIONS>
## Analysis Approach:

### 1. Understand the Question
- Identify what specific insights or data the user is seeking
- Determine the appropriate time period (default: previous week)
- Consider which stores/zones are relevant

### 2. Select Appropriate MCP Tools
**CRITICAL: Database Architecture Rules**

**ğŸš¨ IMPORTANT DATABASE ROUTING:**
- **POS/ë§¤ì¶œ ë°ì´í„°** = `cu_base` ë°ì´í„°ë² ì´ìŠ¤ (ì¤‘ì•™ ì„œë²„) â†’ **`pos_` ì‹œì‘í•˜ëŠ” íˆ´ë§Œ ì‚¬ìš©**
- **ê³ ê° í–‰ë™ ë°ì´í„°** = `plusinsight` ë°ì´í„°ë² ì´ìŠ¤ (ë§¤ì¥ë³„) â†’ **`insight_` ë˜ëŠ” `diagnose_` íˆ´ ì‚¬ìš©**

**ğŸª POS Sales Data (Central cu_base hub only):**
**âš ï¸ WORKFLOW: .env connection â†’ cu_base database â†’ cu_revenue_total table**
- Connection: Direct .env credentials (CLICKHOUSE_HOST, CLICKHOUSE_PORT, etc.)
- Database: cu_base (the central hub that also contains store connection registry)
- Table: `cu_revenue_total` (ALL stores' POS data in one table, filter by store_nm)
- Tools: `pos_daily_sales_stats`, `receipt_ranking`, `sales_ranking`, `volume_ranking`, `event_product_analysis`, `ranking_event_product`, `co_purchase_trend`
**ğŸš¨ POS data is in the SAME central database that contains store connection info!**

**ğŸ‘¥ Customer Behavior Data (Store-specific plusinsight databases):**
**âš ï¸ WORKFLOW: .env connection â†’ cu_base â†’ site_db_connection_config â†’ individual store's plusinsight DB**
- Step 1: Connect to cu_base using .env credentials  
- Step 2: Query site_db_connection_config table to get store's connection info
- Step 3: Connect to that store's individual plusinsight database
- Tables: `line_in_out_individual`, `customer_behavior_event`, `zone`, `sales_funnel`, `two_step_flow`, `detected_time`
- Tools: `diagnose_*` (except purchase_conversion_rate), `insight_*`, `shelf_*`

**ğŸ”„ Cross-Database Analysis:**
- `diagnose_purchase_conversion_rate`: Uses BOTH cu_base + plusinsight

**ğŸ¬ Store Management:**
- `get_available_sites`: ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì¥ ëª©ë¡
- `validate_site`: ë§¤ì¥ëª… ìœ íš¨ì„± ê²€ì¦

### 3. Provide Context-Rich Insights
- Always explain what the data means in business terms
- Compare against benchmarks and historical performance
- Identify actionable opportunities and risks
- Quantify potential impact where possible

### 4. Korean Language Support
- Respond in Korean when user asks in Korean
- Use appropriate business terminology
- Maintain professional tone
- Include success metrics and monitoring approach

## Quality Standards:
- **Accuracy**: All numbers must be verified and properly sourced
- **Relevance**: Focus on insights that drive business decisions
- **Actionability**: Every recommendation must be specific and implementable
- **Timeliness**: Distinguish between immediate, short-term, and strategic actions
- **Confidence**: Indicate certainty levels for predictions and recommendations
</INSTRUCTIONS>

----

## Response Guidelines:
- **Be Direct**: Answer the specific question asked
- **Use Data**: Support insights with actual numbers from tools
- **Stay Relevant**: Focus on actionable business insights
- **Be Concise**: Provide clear, structured responses
- **Show Sources**: Mention which MCP tools were used

Remember: You have direct access to comprehensive retail analytics data. Use the MCP tools effectively to provide accurate, data-driven insights that help optimize store performance.
"""

# ë™ì  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
def get_system_prompt() -> str:
    """í˜„ì¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜ (ë™ì  ìŠ¤í‚¤ë§ˆ í¬í•¨)"""
    return build_dynamic_system_prompt()

# ëª¨ë¸ í† í° ì •ë³´
OUTPUT_TOKEN_INFO = {
    "gpt-5": {"max_tokens": 16384, "temperature": 0.1},
    "gpt-4o": {"max_tokens": 16384, "temperature": 0.1},
}

# ì„¤ì • ë¡œë“œ í•¨ìˆ˜
def load_config_from_json():
    """
    ì„¤ì •ì„ JSON íŒŒì¼ì—ì„œ ë¡œë“œí•©ë‹ˆë‹¤.
    íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        dict: ë¡œë“œëœ ì„¤ì •
    """
    default_config = {
        "get_current_time": {
            "command": "python",
            "args": ["./mcp_server_time.py"],
            "transport": "stdio"
        }
    }
    
    try:
        if os.path.exists(CONFIG_FILE_PATH):
            with open(CONFIG_FILE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # íŒŒì¼ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìƒì„±
            save_config_to_json(default_config)
            return default_config
    except Exception as e:
        print(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
        return default_config

# ì„¤ì • ì €ì¥ í•¨ìˆ˜
def save_config_to_json(config):
    """
    ì„¤ì •ì„ JSON íŒŒì¼ì— ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        config (dict): ì €ì¥í•  ì„¤ì •
    
    Returns:
        bool: ì €ì¥ ì„±ê³µ ì—¬ë¶€
    """
    try:
        with open(CONFIG_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        print(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
        return False

# MCP í´ë¼ì´ì–¸íŠ¸ì™€ ì—ì´ì „íŠ¸ ì €ì¥ì†Œ
mcp_clients = {}
agents = {}
conversation_histories = {}
agent_models = {}  # ìŠ¤ë ˆë“œë³„ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ ì €ì¥
tool_count = 0  # ì „ì—­ ë³€ìˆ˜ë¡œ tool_count ì„ ì–¸

# ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì €ì¥ì†Œ
multi_agent_workflows = {}  # ìŠ¤ë ˆë“œë³„ ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°

# ìš”ì²­ ë° ì‘ë‹µ ëª¨ë¸ ì •ì˜
class Message(BaseModel):
    role: str
    content: str
    attachment_path: Optional[str] = None  # ì²¨ë¶€ íŒŒì¼ ê²½ë¡œ ì¶”ê°€

class MessageResponse(BaseModel):
    messages: List[Message]
    thread_id: str

class QueryRequest(BaseModel):
    query: str
    thread_id: Optional[str] = None
    model: str = "gpt-4o"
    timeout_seconds: int = 120
    recursion_limit: int = 100
    use_multi_agent: bool = True  # ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‚¬ìš© ì—¬ë¶€

class QueryResponse(BaseModel):
    response: str
    tool_info: Optional[str] = None
    thread_id: str

class ToolRequest(BaseModel):
    tool_config: Dict[str, Any]

class SettingsResponse(BaseModel):
    tool_count: int
    available_models: List[str]
    current_config: Dict[str, Any]

class ThreadResponse(BaseModel):
    thread_id: str

class FileUploadResponse(BaseModel):
    file_path: str
    file_name: str
    file_size: int

# FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •
@asynccontextmanager
async def lifespan(app: FastAPI):
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì„¤ì • ë¡œë“œ
    if not os.path.exists(ABSOLUTE_UPLOAD_DIR):
        os.makedirs(ABSOLUTE_UPLOAD_DIR)
    print(f"ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ê²½ë¡œ: {ABSOLUTE_UPLOAD_DIR}")
    yield
    # ì• í”Œë¦¬ì¼€ì´ì…˜ ì¢…ë£Œ ì‹œ ëª¨ë“  MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ
    for client in mcp_clients.values():
        try:
            await client.__aexit__(None, None, None)
        except Exception as e:
            print(f"MCP í´ë¼ì´ì–¸íŠ¸ ì¢…ë£Œ ì˜¤ë¥˜: {str(e)}")

# íŒŒì¼ ì—…ë¡œë“œ í¬ê¸° ì œí•œì„ 300MBë¡œ ì„¤ì •
app = FastAPI(title="MCP Tool Agent API", lifespan=lifespan)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ì‹¤ì œ ë°°í¬ ì‹œì—ëŠ” íŠ¹ì • ì¶œì²˜ë§Œ í—ˆìš©ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì •ì  íŒŒì¼ ì„œë¹™ ì„¤ì • (ì—…ë¡œë“œ íŒŒì¼ ì•¡ì„¸ìŠ¤ìš©)
app.mount("/uploads", StaticFiles(directory=ABSOLUTE_UPLOAD_DIR), name="uploads")

# HTML ë³´ê³ ì„œ ì„œë¹™ ì„¤ì •
REPORT_DIR = os.path.join(BASE_DIR, "report")
if not os.path.exists(REPORT_DIR):
    os.makedirs(REPORT_DIR, exist_ok=True)
app.mount("/reports", StaticFiles(directory=REPORT_DIR), name="reports")

# ì—ì´ì „íŠ¸ ì´ˆê¸°í™” í•¨ìˆ˜
async def initialize_agent(thread_id: str, model: str = "gpt-4o", mcp_config=None):
    """
    MCP ì„¸ì…˜ê³¼ ì—ì´ì „íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

    Args:
        thread_id: ëŒ€í™” ìŠ¤ë ˆë“œ ID
        model: ì‚¬ìš©í•  ëª¨ë¸
        mcp_config: MCP ë„êµ¬ ì„¤ì • ì •ë³´(JSON). Noneì¸ ê²½ìš° ê¸°ë³¸ ì„¤ì • ì‚¬ìš©

    Returns:
        bool: ì´ˆê¸°í™” ì„±ê³µ ì—¬ë¶€
    """
    try:
        global tool_count  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸
        
        # ê¸°ì¡´ í´ë¼ì´ì–¸íŠ¸ê°€ ìˆìœ¼ë©´ ì‚­ì œ
        if thread_id in mcp_clients:
            del mcp_clients[thread_id]
        
        if mcp_config is None:
            # ì„¤ì • íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ
            mcp_config = load_config_from_json()
        
        # ìƒˆë¡œìš´ API ì‚¬ìš© ë°©ì‹ ì ìš©
        client = MultiServerMCPClient(mcp_config)
        tools = await client.get_tools()  # get_tools ë©”ì„œë“œê°€ ì´ì œ ë¹„ë™ê¸°ì‹ì…ë‹ˆë‹¤
        tool_count = len(tools)  # ì „ì—­ ë³€ìˆ˜ì— í• ë‹¹
        
        print(f"ğŸ” [TOOLS] ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ê°œìˆ˜: {tool_count}")
        for i, tool in enumerate(tools[:3]):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
            print(f"ğŸ” [TOOLS] ë„êµ¬ {i+1}: {getattr(tool, 'name', 'name ì—†ìŒ')}")
            if hasattr(tool, 'description'):
                print(f"  ì„¤ëª…: {tool.description[:100]}...")
        if len(tools) > 3:
            print(f"ğŸ” [TOOLS] ... ì™¸ {len(tools)-3}ê°œ ë”")
        
        # OpenAI ëª¨ë¸ ì‚¬ìš©
        model_info = OUTPUT_TOKEN_INFO[model]
        llm_kwargs = {
            "model": model,
            "max_tokens": model_info["max_tokens"],
        }
        
        # temperatureê°€ ì„¤ì •ë˜ì–´ ìˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€ (o3ëŠ” temperature ì§€ì›í•˜ì§€ ì•ŠìŒ)
        if model_info["temperature"] is not None:
            llm_kwargs["temperature"] = model_info["temperature"]
            
        llm = ChatOpenAI(**llm_kwargs)
        
        agent = create_react_agent(
            llm,
            tools,
            checkpointer=MemorySaver(),
            prompt=get_system_prompt(),
        )
        
        # í´ë¼ì´ì–¸íŠ¸ì™€ ì—ì´ì „íŠ¸ ì €ì¥
        mcp_clients[thread_id] = client
        agents[thread_id] = agent
        conversation_histories[thread_id] = []
        agent_models[thread_id] = model  # í˜„ì¬ ëª¨ë¸ ì €ì¥
        
        return True
    except Exception as e:
        print(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì˜¤ë¥˜: {str(e)}")
        return False

# ìŠ¤íŠ¸ë¦¬ë° ì½œë°± í´ë˜ìŠ¤
class StreamingResponse:
    def __init__(self):
        self.accumulated_text = []
        self.accumulated_tool = []
        print(f"accumulated_text: {self.accumulated_text}")
        print(f"accumulated_tool: {self.accumulated_tool}")
    
    def callback(self, message: dict):
        # ë””ë²„ê¹…ì„ ìœ„í•œ ë©”ì‹œì§€ ë¡œê¹…
        # print(f"ë©”ì‹œì§€ íƒ€ì…: {type(message)}")
        # print(f"ë©”ì‹œì§€ í‚¤: {message.keys() if hasattr(message, 'keys') else 'No keys'}")
        
        message_content = message.get("content", None)
        # print(f"ë©”ì‹œì§€ ë‚´ìš© íƒ€ì…: {type(message_content)}")
        
        if isinstance(message_content, AIMessageChunk):
            content = message_content.content
            # ì½˜í…ì¸ ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ ê²½ìš° (Claude ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            if isinstance(content, list) and len(content) > 0:
                message_chunk = content[0]
                # í…ìŠ¤íŠ¸ íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                if message_chunk["type"] == "text":
                    self.accumulated_text.append(message_chunk["text"])
                # ë„êµ¬ ì‚¬ìš© íƒ€ì…ì¸ ê²½ìš° ì²˜ë¦¬
                elif message_chunk["type"] == "tool_use":
                    if "partial_json" in message_chunk:
                        tool_content = message_chunk["partial_json"]
                        formatted_tool = f"**ë„êµ¬ ì´ë¦„**: `{tool_content.get('name', 'ì•Œ ìˆ˜ ì—†ìŒ')}`\n\n**ì…ë ¥ê°’**:\n```json\n{json.dumps(tool_content.get('args', {}), indent=2, ensure_ascii=False)}\n```\n"
                        self.accumulated_tool.append(formatted_tool)
                    else:
                        tool_call_chunks = message_content.tool_call_chunks
                        tool_call_chunk = tool_call_chunks[0]
                        formatted_tool = f"**ë„êµ¬ í˜¸ì¶œ ì •ë³´**:\n\n```json\n{json.dumps(tool_call_chunk, indent=2, ensure_ascii=False)}\n```\n"
                        self.accumulated_tool.append(formatted_tool)
            # tool_calls ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (OpenAI ëª¨ë¸ ë“±ì—ì„œ ì£¼ë¡œ ë°œìƒ)
            elif (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls[0]["name"]) > 0
            ):
                # ğŸ” ì›ì‹œ tool_calls ë°ì´í„° í™•ì¸
                # ë„êµ¬ í˜¸ì¶œ ì²˜ë¦¬
                tool_call_info = message_content.tool_calls[0]
                tool_name = tool_call_info.get("name", "ì•Œ ìˆ˜ ì—†ìŒ")
                tool_args = tool_call_info.get("arguments", {})
                
                # ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ ë„êµ¬ ì •ë³´ í¬ë§·íŒ…
                formatted_tool = f"**ë„êµ¬ ì´ë¦„**: `{tool_name}`\n\n**ì…ë ¥ê°’**:\n```json\n{json.dumps(tool_args, indent=2, ensure_ascii=False)}\n```\n"
                self.accumulated_tool.append(formatted_tool)
                
                # ì½˜ì†”ì— ë„êµ¬ í˜¸ì¶œ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                print(f"ë„êµ¬ í˜¸ì¶œ ê°ì§€: {tool_name}")
                print(f"ì›ë³¸ tool_call_info ì „ì²´: {tool_call_info}")
                print(f"tool_call_info.keys(): {list(tool_call_info.keys())}")
                
                # args í•„ë“œ ì§ì ‘ í™•ì¸
                if 'args' in tool_call_info:
                    print(f"args í•„ë“œ: {tool_call_info['args']}")
                    print(f"args í•„ë“œ íƒ€ì…: {type(tool_call_info['args'])}")
                    print(f"args í•„ë“œ ë‚´ìš©: {tool_call_info['args']}")
                    print(f"args í•„ë“œ ë‚´ìš© íƒ€ì…: {type(tool_call_info['args'])}")
                    print(f"args í•„ë“œ ë‚´ìš© ë‚´ìš©: {tool_call_info['args']}")
                    print(f"args í•„ë“œ ë‚´ìš© ë‚´ìš© íƒ€ì…: {type(tool_call_info['args'])}")
                
                # arguments í•„ë“œ í™•ì¸
                if 'arguments' in tool_call_info:
                    print(f"getìœ¼ë¡œ íŒŒì‹±ëœ ì¸ì: {tool_args}")
                    print(f"íŒŒì‹±ëœ ì¸ì íƒ€ì…: {type(tool_args)}")
                    
                if isinstance(tool_args, str):
                    try:
                        parsed_args = json.loads(tool_args)
                        print(f"JSON íŒŒì‹±ëœ ì¸ì: {parsed_args}")
                    except Exception as e:
                        print(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ë¬¸ìì—´: {repr(tool_args)}, ì˜¤ë¥˜: {e}")
            # ë‹¨ìˆœ ë¬¸ìì—´ì¸ ê²½ìš° ì²˜ë¦¬
            elif isinstance(content, str):
                self.accumulated_text.append(content)
            # ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬ í˜¸ì¶œ ì •ë³´ê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                tool_call_info = message_content.invalid_tool_calls[0]
                formatted_tool = f"**ìœ íš¨í•˜ì§€ ì•Šì€ ë„êµ¬ í˜¸ì¶œ**:\n\n```json\n{json.dumps(tool_call_info, indent=2, ensure_ascii=False)}\n```\n"
                self.accumulated_tool.append(formatted_tool)
            # tool_call_chunks ì†ì„±ì´ ìˆëŠ” ê²½ìš° ì²˜ë¦¬
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                tool_call_chunk = message_content.tool_call_chunks[0]
                formatted_tool = f"**ë„êµ¬ í˜¸ì¶œ**:\n\n```json\n{json.dumps(tool_call_chunk, indent=2, ensure_ascii=False)}\n```\n"
                self.accumulated_tool.append(formatted_tool)
            # additional_kwargsì— tool_callsê°€ ìˆëŠ” ê²½ìš° ì²˜ë¦¬ (ë‹¤ì–‘í•œ ëª¨ë¸ í˜¸í™˜ì„± ì§€ì›)
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
            ):
                tool_call_info = message_content.additional_kwargs["tool_calls"][0]
                tool_name = tool_call_info.get("name", "ì•Œ ìˆ˜ ì—†ìŒ")
                tool_args = tool_call_info.get("arguments", {})
                
                formatted_tool = f"**ë„êµ¬ ì´ë¦„**: `{tool_name}`\n\n**ì…ë ¥ê°’**:\n```json\n{json.dumps(tool_args, indent=2, ensure_ascii=False)}\n```\n"
                self.accumulated_tool.append(formatted_tool)
                
                # ì½˜ì†”ì— ë„êµ¬ í˜¸ì¶œ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
                print(f"ë„êµ¬ í˜¸ì¶œ ê°ì§€(additional_kwargs): {tool_name}")
                print(f"ì›ë³¸ additional_kwargs ì „ì²´: {message_content.additional_kwargs}")
                print(f"tool_calls ë°°ì—´: {message_content.additional_kwargs.get('tool_calls', [])}")
                
                if message_content.additional_kwargs.get('tool_calls'):
                    first_tool = message_content.additional_kwargs['tool_calls'][0]
                    print(f"ì²« ë²ˆì§¸ tool_call ì „ì²´: {first_tool}")
                    print(f"tool_call keys: {list(first_tool.keys()) if isinstance(first_tool, dict) else 'Not dict'}")
                    
                    # function í•„ë“œ í™•ì¸
                    if 'function' in first_tool:
                        func_info = first_tool['function']
                        print(f"function í•„ë“œ: {func_info}")
                        if 'arguments' in func_info:
                            print(f"function.arguments: {func_info['arguments']}")
                            print(f"function.arguments íƒ€ì…: {type(func_info['arguments'])}")
                
                print(f"getìœ¼ë¡œ íŒŒì‹±ëœ ì¸ì: {tool_args}")
                print(f"íŒŒì‹±ëœ ì¸ì íƒ€ì…: {type(tool_args)}")
                
                if isinstance(tool_args, str):
                    try:
                        parsed_args = json.loads(tool_args)
                        print(f"JSON íŒŒì‹±ëœ ì¸ì: {parsed_args}")
                    except Exception as e:
                        print(f"JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ë¬¸ìì—´: {repr(tool_args)}, ì˜¤ë¥˜: {e}")
        # ë„êµ¬ ë©”ì‹œì§€ì¸ ê²½ìš° ì²˜ë¦¬ (ë„êµ¬ì˜ ì‘ë‹µ)
        elif hasattr(message_content, 'content') and isinstance(message_content, ToolMessage):
            tool_content = message_content.content
            # ë„êµ¬ ì‘ë‹µ ì •ë³´ë¥¼ ë§ˆí¬ë‹¤ìš´ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
            formatted_tool = f"**ë„êµ¬ ì‘ë‹µ ê²°ê³¼**:\n\n```\n{tool_content}\n```\n"
            self.accumulated_tool.append(formatted_tool)
            
            # ì½˜ì†”ì— ë„êµ¬ ì‘ë‹µ ì •ë³´ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
            print(f"ë„êµ¬ ì‘ë‹µ ë‚´ìš©: {tool_content[:200]}..." if len(tool_content) > 200 else tool_content)
        # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
        elif hasattr(message_content, 'content') and isinstance(message_content.content, str):
            self.accumulated_text.append(message_content.content)
        
        return None
    
    def get_results(self):
        final_text = "".join(self.accumulated_text)
        final_tool = "".join(self.accumulated_tool)
        
        print(f"ìµœì¢… í…ìŠ¤íŠ¸ ê¸¸ì´: {len(final_text)}")
        print(f"ìµœì¢… ë„êµ¬ ì •ë³´ ê¸¸ì´: {len(final_tool)}")
        
        return final_text, final_tool

# ì§ˆë¬¸ ì²˜ë¦¬ í•¨ìˆ˜
async def process_query(thread_id: str, query: str, timeout_seconds=60, recursion_limit=100):
    """
    ì‚¬ìš©ì ì§ˆë¬¸ì„ ì²˜ë¦¬í•˜ê³  ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        thread_id: ëŒ€í™” ìŠ¤ë ˆë“œ ID
        query: ì‚¬ìš©ì ì§ˆë¬¸ í…ìŠ¤íŠ¸
        timeout_seconds: ì‘ë‹µ ìƒì„± ì œí•œ ì‹œê°„(ì´ˆ)
        recursion_limit: ì¬ê·€ í˜¸ì¶œ ì œí•œ íšŸìˆ˜

    Returns:
        response: ì—ì´ì „íŠ¸ ì‘ë‹µ ê°ì²´
        final_text: ìµœì¢… í…ìŠ¤íŠ¸ ì‘ë‹µ
        final_tool: ìµœì¢… ë„êµ¬ í˜¸ì¶œ ì •ë³´
    """
    try:
        if thread_id in agents:
            streaming_response = StreamingResponse()
            
            try:                
                messages = [HumanMessage(content=query)]
                # ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹œì‘
                
                response = await asyncio.wait_for(
                    astream_graph(
                        agents[thread_id],
                        {"messages": messages},
                        callback=streaming_response.callback,
                        config=RunnableConfig(
                            recursion_limit=recursion_limit,
                            thread_id=thread_id,
                        ),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"ìš”ì²­ ì‹œê°„ì´ {timeout_seconds}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                return {"error": error_msg}, error_msg, ""

            print("StreamingResponse ì™„ë£Œ")
            final_text, final_tool = streaming_response.get_results()
            
            return response, final_text, final_tool
        else:
            return {"error": "ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}, "ì—ì´ì „íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", ""
    except Exception as e:
        import traceback
        error_msg = f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""

# API ì—”ë“œí¬ì¸íŠ¸ ì •ì˜
@app.get("/api/settings")
async def get_settings():
    """í˜„ì¬ ì„¤ì • ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("[GET] /api/settings")
    global tool_count  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸
    
    config = load_config_from_json()
    
    # MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì•„ì§ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì„ì‹œ í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ì—¬ ë„êµ¬ ê°œìˆ˜ í™•ì¸
    if tool_count == 0:
        try:
            # ìƒˆë¡œìš´ API ì‚¬ìš© ë°©ì‹ ì ìš©
            temp_client = MultiServerMCPClient(config)
            tools = await temp_client.get_tools()
            tool_count = len(tools)
        except Exception as e:
            print(f"ë„êµ¬ ê°œìˆ˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„¤ì • íŒŒì¼ì˜ ë„êµ¬ ê°œìˆ˜ë¥¼ ì‚¬ìš©
            tool_count = len(config)
    
    return SettingsResponse(
        tool_count=tool_count,
        available_models=list(OUTPUT_TOKEN_INFO.keys()),
        current_config=config
    )

@app.post("/api/settings")
async def update_settings(tool_config: ToolRequest):
    """ì„¤ì •ì„ ì—…ë°ì´íŠ¸í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤."""
    print("[POST] /api/settings")
    global tool_count  # ì „ì—­ ë³€ìˆ˜ ì‚¬ìš© ì„ ì–¸
    
    success = save_config_to_json(tool_config.tool_config)
    if not success:
        raise HTTPException(status_code=500, detail="ì„¤ì • ì €ì¥ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    # ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ë©´ ë„êµ¬ ê°œìˆ˜ë„ ì—…ë°ì´íŠ¸
    try:
        # ìƒˆë¡œìš´ API ì‚¬ìš© ë°©ì‹ ì ìš©
        temp_client = MultiServerMCPClient(tool_config.tool_config)
        tools = await temp_client.get_tools()
        tool_count = len(tools)
    except Exception as e:
        print(f"ë„êµ¬ ê°œìˆ˜ ì—…ë°ì´íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì„¤ì • íŒŒì¼ì˜ ë„êµ¬ ê°œìˆ˜ë¥¼ ì‚¬ìš©
        tool_count = len(tool_config.tool_config)
    
    return {
        "success": True, 
        "message": "ì„¤ì •ì´ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.", 
        "tool_count": tool_count
    }

@app.post("/api/threads")
async def create_thread():
    """ìƒˆë¡œìš´ ëŒ€í™” ìŠ¤ë ˆë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    print("[POST] /api/threads")
    thread_id = random_uuid()
    await initialize_agent(thread_id)
    return ThreadResponse(thread_id=thread_id)

@app.get("/api/threads/{thread_id}")
async def get_thread(thread_id: str):
    """íŠ¹ì • ìŠ¤ë ˆë“œì˜ ëŒ€í™” ê¸°ë¡ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    print("[GET] /api/threads/{thread_id}")
    if thread_id not in conversation_histories:
        raise HTTPException(status_code=404, detail="ìŠ¤ë ˆë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return MessageResponse(
        messages=conversation_histories[thread_id],
        thread_id=thread_id
    )

@app.delete("/api/threads/{thread_id}")
async def delete_thread(thread_id: str):
    """ìŠ¤ë ˆë“œë¥¼ ì‚­ì œí•©ë‹ˆë‹¤."""
    print("[DELETE] /api/threads/{thread_id}")
    if thread_id in mcp_clients:
        # ìƒˆ ë²„ì „ì—ì„œëŠ” context manager ì¸í„°í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì§ì ‘ ì‚­ì œë§Œ í•¨
        del mcp_clients[thread_id]
    
    if thread_id in agents:
        del agents[thread_id]
    
    if thread_id in conversation_histories:
        del conversation_histories[thread_id]
    
    return {"success": True, "message": "ìŠ¤ë ˆë“œê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤."}

@app.post("/api/upload", response_model=FileUploadResponse)
async def upload_file(file: UploadFile = File(...)):
    """
    íŒŒì¼ì„ ì„œë²„ì— ì—…ë¡œë“œí•©ë‹ˆë‹¤.
    """
    print(f"[POST] /api/upload - íŒŒì¼ ì´ë¦„: {file.filename}, í¬ê¸°: {file.size if hasattr(file, 'size') else 'ì•Œ ìˆ˜ ì—†ìŒ'}")
    try:
        # ê³ ìœ  íŒŒì¼ëª… ìƒì„± (íŒŒì¼ëª… ì¶©ëŒ ë°©ì§€)
        file_extension = os.path.splitext(file.filename)[1] if file.filename else ""
        unique_filename = f"{uuid.uuid4()}{file_extension}"
        file_path = os.path.join(ABSOLUTE_UPLOAD_DIR, unique_filename)
        
        # íŒŒì¼ ì €ì¥
        with open(file_path, "wb") as f:
            shutil.copyfileobj(file.file, f)
        
        # íŒŒì¼ ì •ë³´ ë°˜í™˜
        file_size = os.path.getsize(file_path)
        print(f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file_path}, í¬ê¸°: {file_size}")
        
        # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
        response_data = FileUploadResponse(
            file_path=file_path,  # ì ˆëŒ€ ê²½ë¡œë¡œ ë°˜í™˜
            file_name=file.filename,
            file_size=file_size
        )
        print(f"ì‘ë‹µ ë°ì´í„°: {response_data}")
        return response_data
    except Exception as e:
        print(f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    finally:
        file.file.close()

@app.post("/api/threads/{thread_id}/query")
async def query_agent(thread_id: str, request: QueryRequest, background_tasks: BackgroundTasks):
    """
    ì—ì´ì „íŠ¸ì— ì§ˆë¬¸ì„ ì „ì†¡í•˜ê³  ì‘ë‹µì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    print(f"[POST] /api/threads/{thread_id}/query: {request.query}")
    # ìŠ¤ë ˆë“œ IDê°€ ì œê³µë˜ì§€ ì•Šì€ ê²½ìš° ìƒˆë¡œ ìƒì„±
    if not thread_id:
        thread_id = random_uuid()
    
    # ì—ì´ì „íŠ¸ê°€ ì—†ê±°ë‚˜ ëª¨ë¸ì´ ë³€ê²½ëœ ê²½ìš° ì¬ì´ˆê¸°í™”
    need_init = (
        thread_id not in agents or 
        thread_id not in agent_models or 
        agent_models.get(thread_id) != request.model
    )
    
    if need_init:
        print(f"ì—ì´ì „íŠ¸ ì´ˆê¸°í™”/ì¬ì´ˆê¸°í™” í•„ìš”: thread_id={thread_id}, model={request.model}")
        # ì—ì´ì „íŠ¸ ì´ˆê¸°í™”
        success = await initialize_agent(
            thread_id, 
            model=request.model
        )
        
        if not success:
            raise HTTPException(status_code=500, detail="ì—ì´ì „íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
    
    # ì²¨ë¶€ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
    attachment_path = None
    if "[ì²¨ë¶€ íŒŒì¼: " in request.query:
        try:
            # ì²¨ë¶€ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ
            start_idx = request.query.find("[ì²¨ë¶€ íŒŒì¼: ") + len("[ì²¨ë¶€ íŒŒì¼: ")
            end_idx = request.query.find("]", start_idx)
            attachment_path = request.query[start_idx:end_idx]
            
            # ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
            if attachment_path.startswith("./uploads/") or attachment_path.startswith("/uploads/"):
                file_name = os.path.basename(attachment_path)
                attachment_path = os.path.join(ABSOLUTE_UPLOAD_DIR, file_name)
                print(f"ì²¨ë¶€ íŒŒì¼ ê²½ë¡œ ë³€í™˜: {attachment_path}")
            
            # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
            if not os.path.exists(attachment_path):
                print(f"ê²½ê³ : íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {attachment_path}")
                return {
                    "response": f"ì˜¤ë¥˜: íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œ: {attachment_path}",
                    "thread_id": thread_id
                }
            else:
                print(f"íŒŒì¼ í™•ì¸ ì™„ë£Œ: {attachment_path} (í¬ê¸°: {os.path.getsize(attachment_path)} bytes)")
        except Exception as e:
            print(f"ì²¨ë¶€ íŒŒì¼ ê²½ë¡œ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
    
    try:
        # ëŒ€ìš©ëŸ‰ íŒŒì¼ì´ í¬í•¨ëœ ê²½ìš° íƒ€ì„ì•„ì›ƒ ê°’ ì¦ê°€
        timeout_value = request.timeout_seconds
        if attachment_path and os.path.exists(attachment_path):
            file_size = os.path.getsize(attachment_path)
            # íŒŒì¼ í¬ê¸°ê°€ 10MBë¥¼ ì´ˆê³¼í•˜ë©´ íƒ€ì„ì•„ì›ƒ ê°’ ì¦ê°€
            if file_size > 10 * 1024 * 1024:
                timeout_value = max(timeout_value, 300)  # ìµœì†Œ 300ì´ˆ
                print(f"ëŒ€ìš©ëŸ‰ íŒŒì¼ ê°ì§€: íƒ€ì„ì•„ì›ƒ ê°’ì„ {timeout_value}ì´ˆë¡œ ì¦ê°€")
        
        # ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì‹œì‘ ë¡œê¹…
        print(f"ëŒ€í™” ì²˜ë¦¬ ì‹œì‘: íƒ€ì„ì•„ì›ƒ={timeout_value}ì´ˆ, ì¬ê·€ ì œí•œ={request.recursion_limit}")
        
        # ì§ˆë¬¸ ì²˜ë¦¬ - ë©€í‹° ì—ì´ì „íŠ¸ ì‹œìŠ¤í…œ ì‚¬ìš© ì—¬ë¶€ì— ë”°ë¼ ë¶„ê¸°
        if request.use_multi_agent and MULTI_AGENT_AVAILABLE:
            try:
                # ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” (í•„ìš”ì‹œ)
                if thread_id not in multi_agent_workflows:
                    # MCP í´ë¼ì´ì–¸íŠ¸ ê°€ì ¸ì˜¤ê¸°
                    mcp_client = mcp_clients.get(thread_id)
                    if not mcp_client:
                        # MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ ReAct ì—ì´ì „íŠ¸ë¡œ í´ë°±
                        raise RuntimeError("MCP í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•ŠìŒ")
                    
                    # LLM ëª¨ë¸ ì´ˆê¸°í™”
                    model_config = OUTPUT_TOKEN_INFO.get(request.model, OUTPUT_TOKEN_INFO["gpt-4o"])
                    llm_model = ChatOpenAI(
                        model=request.model,  # ì„ íƒí•œ ëª¨ë¸ ê·¸ëŒ€ë¡œ ì‚¬ìš© (gpt-5, gpt-4o)
                        temperature=model_config["temperature"],
                        max_tokens=model_config["max_tokens"]
                    )
                    
                    multi_agent_workflows[thread_id] = MultiAgentWorkflow(
                        mcp_client=mcp_client,
                        model=llm_model
                    )
                    print(f"âœ¨ [MULTI-AGENT] ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™” ì™„ë£Œ: {thread_id}")
                
                # ë©€í‹° ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°ë¡œ ì¿¼ë¦¬ ì²˜ë¦¬
                workflow_result = await multi_agent_workflows[thread_id].execute(
                    user_query=request.query,
                    session_id=thread_id
                )
                
                final_text = workflow_result.get("final_insight", "ë©€í‹° ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ")
                final_tool = ""  # ë©€í‹° ì—ì´ì „íŠ¸ëŠ” ë„êµ¬ ì •ë³´ë¥¼ ë³„ë„ë¡œ ì œê³µí•˜ì§€ ì•ŠìŒ
                
                print(f"âœ¨ [MULTI-AGENT] ë©€í‹° ì—ì´ì „íŠ¸ ë¶„ì„ ì™„ë£Œ: {len(final_text)} chars")
                
            except Exception as e:
                print(f"âš ï¸ [MULTI-AGENT] ë©€í‹° ì—ì´ì „íŠ¸ ì²˜ë¦¬ ì‹¤íŒ¨, ReAct ì—ì´ì „íŠ¸ë¡œ í´ë°±: {e}")
                # ê¸°ë³¸ ReAct ì—ì´ì „íŠ¸ë¡œ í´ë°±
                _, final_text, final_tool = await process_query(
                    thread_id, 
                    request.query,
                    timeout_seconds=timeout_value,
                    recursion_limit=request.recursion_limit
                )
        else:
            # ê¸°ë³¸ ReAct ì—ì´ì „íŠ¸ ì‚¬ìš©
            print(f"ğŸ”§ [REACT] ê¸°ë³¸ ReAct ì—ì´ì „íŠ¸ ì‚¬ìš©")
            _, final_text, final_tool = await process_query(
                thread_id, 
                request.query,
                timeout_seconds=timeout_value,
                recursion_limit=request.recursion_limit
            )
        
        print(f"final_text ê¸¸ì´: {len(final_text)}")
        if final_tool:
            print(f"final_tool ê¸¸ì´: {len(final_tool)}")
            print(f"final_tool ìƒ˜í”Œ: {final_tool[:200]}..." if len(final_tool) > 200 else final_tool)
        
        # ëŒ€í™” ê¸°ë¡ì— ì¶”ê°€
        conversation_histories[thread_id].append(
            Message(
                role="user", 
                content=request.query,
                attachment_path=attachment_path
            )
        )
        conversation_histories[thread_id].append(
            Message(
                role="assistant", 
                content=final_text
            )
        )
        
        # ë„êµ¬ ì •ë³´ê°€ ìˆìœ¼ë©´ í•´ë‹¹ ì •ë³´ ë°˜í™˜
        tool_info = None
        if final_tool:
            tool_info = final_tool
            print(f"ë„êµ¬ ì‚¬ìš© ì •ë³´ ì „ì†¡: ë„êµ¬ ì •ë³´ ê¸¸ì´ {len(tool_info)}")
        
        return QueryResponse(
            response=final_text,
            tool_info=tool_info,
            thread_id=thread_id
        )
    except asyncio.TimeoutError:
        error_msg = f"ìš”ì²­ ì‹œê°„ì´ {timeout_value}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ë‚˜ì¤‘ì— ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
        print(f"ì˜¤ë¥˜: íƒ€ì„ì•„ì›ƒ ë°œìƒ - {error_msg}")
        
        # íƒ€ì„ì•„ì›ƒ ë°œìƒ ì‹œ ëŒ€í™” ê¸°ë¡ì— ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€
        conversation_histories[thread_id].append(
            Message(
                role="user", 
                content=request.query,
                attachment_path=attachment_path
            )
        )
        conversation_histories[thread_id].append(
            Message(
                role="assistant", 
                content=error_msg
            )
        )
        
        return QueryResponse(
            response=error_msg,
            thread_id=thread_id
        )
    except Exception as e:
        import traceback
        error_msg = f"ì§ˆë¬¸ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\n{traceback.format_exc()}"
        print(f"ì˜¤ë¥˜: {error_msg}")
        
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ëŒ€í™” ê¸°ë¡ì— ì˜¤ë¥˜ ë©”ì‹œì§€ ì¶”ê°€
        conversation_histories[thread_id].append(
            Message(
                role="user", 
                content=request.query,
                attachment_path=attachment_path
            )
        )
        conversation_histories[thread_id].append(
            Message(
                role="assistant", 
                content=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
            )
        )
        
        return QueryResponse(
            response=f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
            thread_id=thread_id
        )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000) 